{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install clean-text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI6EeEuabpZ0",
        "outputId": "99a365eb-bf23-4d1c-c690-f1bb2e76d912"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting clean-text\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting ftfy<7.0,>=6.0\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting emoji<2.0.0,>=1.0.0\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.5)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=455593ff2bf43b23b9443c0ac7479dd89e229f76f96ea38b079fade80c8bfe18\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: ftfy, emoji, clean-text\n",
            "Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import tensorflow as tf;\n",
        "import numpy as npp\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import pandas as pd\n",
        "from cleantext import clean\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "52JYo9I8ScOC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RyGrYRDlSBfj"
      },
      "outputs": [],
      "source": [
        "modelToxicityDetector = tf.keras.models.load_model('./toxicityDetector.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_PATH = os.path.join('sample_data','test.csv') # providing the path to the import csv wrt the notebook"
      ],
      "metadata": {
        "id": "9k4im0vzYv1a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(CSV_PATH,encoding='utf-8') #importing csv using pandas"
      ],
      "metadata": {
        "id": "mtvOkjPxY3bT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.duplicated().sum() #duplicated entries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X8kt5rrZDmt",
        "outputId": "14527fce-1628-4c9b-ae24-16b4ec86829a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop_duplicates(keep='first',inplace=True)"
      ],
      "metadata": {
        "id": "dYBPGG8AZSwg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXhokVprZUxr",
        "outputId": "ab297ca4-59dd-4f0f-f8b8-50af75fc5e43"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#removing numbers puncuations\n",
        "data['cleaned'] = data['comment_text'].apply(lambda x:re.sub('[^A-Za-z]',' ' ,x))\n",
        "#lowercasing\n",
        "data['lower'] = data['cleaned'].apply(lambda x:x.lower())\n",
        "#removing punctuations\n",
        "data['rem_punkt'] = data['lower'].apply(lambda x: clean(x, no_punct=True))\n",
        "#tokenizing\n",
        "data['tokenized'] = data['rem_punkt'].apply(lambda x: word_tokenize(x))\n",
        "#removing stop words\n",
        "data['final'] = data['tokenized'].apply(lambda t: [x for x in t if x not in stopwords .words ('english')])\n"
      ],
      "metadata": {
        "id": "J0DZy7xnZb5b"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"final_data\"] = data[\"final\"].apply(lambda x: \" \".join(x))\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "s-NFzXEKZg0P",
        "outputId": "18350ac3-4d3c-493e-dfd6-21033825a92c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      id                                       comment_text  \\\n",
              "0       00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
              "1       0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
              "2       00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
              "3       00017563c3f7919a  :If you have a look back at the source, the in...   \n",
              "4       00017695ad8997eb          I don't anonymously edit articles at all.   \n",
              "...                  ...                                                ...   \n",
              "153159  fffcd0960ee309b5  . \\n i totally agree, this stuff is nothing bu...   \n",
              "153160  fffd7a9a6eb32c16  == Throw from out field to home plate. == \\n\\n...   \n",
              "153161  fffda9e8d6fafa9e  \" \\n\\n == Okinotorishima categories == \\n\\n I ...   \n",
              "153162  fffe8f1340a79fc2  \" \\n\\n == \"\"One of the founding nations of the...   \n",
              "153163  ffffce3fb183ee80  \" \\n :::Stop already. Your bullshit is not wel...   \n",
              "\n",
              "                                                  cleaned  \\\n",
              "0       Yo bitch Ja Rule is more succesful then you ll...   \n",
              "1          From RfC       The title is fine as it is  ...   \n",
              "2               Sources         Zawe Ashton on Lapland...   \n",
              "3        If you have a look back at the source  the in...   \n",
              "4               I don t anonymously edit articles at all    \n",
              "...                                                   ...   \n",
              "153159      i totally agree  this stuff is nothing but...   \n",
              "153160     Throw from out field to home plate        D...   \n",
              "153161          Okinotorishima categories       I see ...   \n",
              "153162            One of the founding nations of the E...   \n",
              "153163         Stop already  Your bullshit is not welc...   \n",
              "\n",
              "                                                    lower  \\\n",
              "0       yo bitch ja rule is more succesful then you ll...   \n",
              "1          from rfc       the title is fine as it is  ...   \n",
              "2               sources         zawe ashton on lapland...   \n",
              "3        if you have a look back at the source  the in...   \n",
              "4               i don t anonymously edit articles at all    \n",
              "...                                                   ...   \n",
              "153159      i totally agree  this stuff is nothing but...   \n",
              "153160     throw from out field to home plate        d...   \n",
              "153161          okinotorishima categories       i see ...   \n",
              "153162            one of the founding nations of the e...   \n",
              "153163         stop already  your bullshit is not welc...   \n",
              "\n",
              "                                                rem_punkt  \\\n",
              "0       yo bitch ja rule is more succesful then you ll...   \n",
              "1                 from rfc the title is fine as it is imo   \n",
              "2                          sources zawe ashton on lapland   \n",
              "3       if you have a look back at the source the info...   \n",
              "4                i don t anonymously edit articles at all   \n",
              "...                                                   ...   \n",
              "153159  i totally agree this stuff is nothing but too ...   \n",
              "153160  throw from out field to home plate does it get...   \n",
              "153161  okinotorishima categories i see your changes a...   \n",
              "153162  one of the founding nations of the eu germany ...   \n",
              "153163  stop already your bullshit is not welcome here...   \n",
              "\n",
              "                                                tokenized  \\\n",
              "0       [yo, bitch, ja, rule, is, more, succesful, the...   \n",
              "1       [from, rfc, the, title, is, fine, as, it, is, ...   \n",
              "2                    [sources, zawe, ashton, on, lapland]   \n",
              "3       [if, you, have, a, look, back, at, the, source...   \n",
              "4       [i, don, t, anonymously, edit, articles, at, all]   \n",
              "...                                                   ...   \n",
              "153159  [i, totally, agree, this, stuff, is, nothing, ...   \n",
              "153160  [throw, from, out, field, to, home, plate, doe...   \n",
              "153161  [okinotorishima, categories, i, see, your, cha...   \n",
              "153162  [one, of, the, founding, nations, of, the, eu,...   \n",
              "153163  [stop, already, your, bullshit, is, not, welco...   \n",
              "\n",
              "                                                    final  \\\n",
              "0       [yo, bitch, ja, rule, succesful, ever, whats, ...   \n",
              "1                                 [rfc, title, fine, imo]   \n",
              "2                        [sources, zawe, ashton, lapland]   \n",
              "3       [look, back, source, information, updated, cor...   \n",
              "4                           [anonymously, edit, articles]   \n",
              "...                                                   ...   \n",
              "153159       [totally, agree, stuff, nothing, long, crap]   \n",
              "153160  [throw, field, home, plate, get, faster, throw...   \n",
              "153161  [okinotorishima, categories, see, changes, agr...   \n",
              "153162  [one, founding, nations, eu, germany, law, ret...   \n",
              "153163  [stop, already, bullshit, welcome, fool, think...   \n",
              "\n",
              "                                               final_data  \n",
              "0       yo bitch ja rule succesful ever whats hating s...  \n",
              "1                                      rfc title fine imo  \n",
              "2                             sources zawe ashton lapland  \n",
              "3       look back source information updated correct f...  \n",
              "4                               anonymously edit articles  \n",
              "...                                                   ...  \n",
              "153159              totally agree stuff nothing long crap  \n",
              "153160  throw field home plate get faster throwing cut...  \n",
              "153161  okinotorishima categories see changes agree co...  \n",
              "153162  one founding nations eu germany law return qui...  \n",
              "153163  stop already bullshit welcome fool think kind ...  \n",
              "\n",
              "[153164 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d215d8af-d448-4800-b700-7d523ac20a58\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>lower</th>\n",
              "      <th>rem_punkt</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>final</th>\n",
              "      <th>final_data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you ll...</td>\n",
              "      <td>yo bitch ja rule is more succesful then you ll...</td>\n",
              "      <td>yo bitch ja rule is more succesful then you ll...</td>\n",
              "      <td>[yo, bitch, ja, rule, is, more, succesful, the...</td>\n",
              "      <td>[yo, bitch, ja, rule, succesful, ever, whats, ...</td>\n",
              "      <td>yo bitch ja rule succesful ever whats hating s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "      <td>From RfC       The title is fine as it is  ...</td>\n",
              "      <td>from rfc       the title is fine as it is  ...</td>\n",
              "      <td>from rfc the title is fine as it is imo</td>\n",
              "      <td>[from, rfc, the, title, is, fine, as, it, is, ...</td>\n",
              "      <td>[rfc, title, fine, imo]</td>\n",
              "      <td>rfc title fine imo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "      <td>Sources         Zawe Ashton on Lapland...</td>\n",
              "      <td>sources         zawe ashton on lapland...</td>\n",
              "      <td>sources zawe ashton on lapland</td>\n",
              "      <td>[sources, zawe, ashton, on, lapland]</td>\n",
              "      <td>[sources, zawe, ashton, lapland]</td>\n",
              "      <td>sources zawe ashton lapland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "      <td>If you have a look back at the source  the in...</td>\n",
              "      <td>if you have a look back at the source  the in...</td>\n",
              "      <td>if you have a look back at the source the info...</td>\n",
              "      <td>[if, you, have, a, look, back, at, the, source...</td>\n",
              "      <td>[look, back, source, information, updated, cor...</td>\n",
              "      <td>look back source information updated correct f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "      <td>I don t anonymously edit articles at all</td>\n",
              "      <td>i don t anonymously edit articles at all</td>\n",
              "      <td>i don t anonymously edit articles at all</td>\n",
              "      <td>[i, don, t, anonymously, edit, articles, at, all]</td>\n",
              "      <td>[anonymously, edit, articles]</td>\n",
              "      <td>anonymously edit articles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153159</th>\n",
              "      <td>fffcd0960ee309b5</td>\n",
              "      <td>. \\n i totally agree, this stuff is nothing bu...</td>\n",
              "      <td>i totally agree  this stuff is nothing but...</td>\n",
              "      <td>i totally agree  this stuff is nothing but...</td>\n",
              "      <td>i totally agree this stuff is nothing but too ...</td>\n",
              "      <td>[i, totally, agree, this, stuff, is, nothing, ...</td>\n",
              "      <td>[totally, agree, stuff, nothing, long, crap]</td>\n",
              "      <td>totally agree stuff nothing long crap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153160</th>\n",
              "      <td>fffd7a9a6eb32c16</td>\n",
              "      <td>== Throw from out field to home plate. == \\n\\n...</td>\n",
              "      <td>Throw from out field to home plate        D...</td>\n",
              "      <td>throw from out field to home plate        d...</td>\n",
              "      <td>throw from out field to home plate does it get...</td>\n",
              "      <td>[throw, from, out, field, to, home, plate, doe...</td>\n",
              "      <td>[throw, field, home, plate, get, faster, throw...</td>\n",
              "      <td>throw field home plate get faster throwing cut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153161</th>\n",
              "      <td>fffda9e8d6fafa9e</td>\n",
              "      <td>\" \\n\\n == Okinotorishima categories == \\n\\n I ...</td>\n",
              "      <td>Okinotorishima categories       I see ...</td>\n",
              "      <td>okinotorishima categories       i see ...</td>\n",
              "      <td>okinotorishima categories i see your changes a...</td>\n",
              "      <td>[okinotorishima, categories, i, see, your, cha...</td>\n",
              "      <td>[okinotorishima, categories, see, changes, agr...</td>\n",
              "      <td>okinotorishima categories see changes agree co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153162</th>\n",
              "      <td>fffe8f1340a79fc2</td>\n",
              "      <td>\" \\n\\n == \"\"One of the founding nations of the...</td>\n",
              "      <td>One of the founding nations of the E...</td>\n",
              "      <td>one of the founding nations of the e...</td>\n",
              "      <td>one of the founding nations of the eu germany ...</td>\n",
              "      <td>[one, of, the, founding, nations, of, the, eu,...</td>\n",
              "      <td>[one, founding, nations, eu, germany, law, ret...</td>\n",
              "      <td>one founding nations eu germany law return qui...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153163</th>\n",
              "      <td>ffffce3fb183ee80</td>\n",
              "      <td>\" \\n :::Stop already. Your bullshit is not wel...</td>\n",
              "      <td>Stop already  Your bullshit is not welc...</td>\n",
              "      <td>stop already  your bullshit is not welc...</td>\n",
              "      <td>stop already your bullshit is not welcome here...</td>\n",
              "      <td>[stop, already, your, bullshit, is, not, welco...</td>\n",
              "      <td>[stop, already, bullshit, welcome, fool, think...</td>\n",
              "      <td>stop already bullshit welcome fool think kind ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153164 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d215d8af-d448-4800-b700-7d523ac20a58')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d215d8af-d448-4800-b700-7d523ac20a58 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d215d8af-d448-4800-b700-7d523ac20a58');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_WORDS = 200000 #no of words in the vocabulory\n",
        "vectorizer = TextVectorization(max_tokens=MAX_WORDS,\n",
        "                               output_sequence_length=1800,\n",
        "                               output_mode='int');\n"
      ],
      "metadata": {
        "id": "ZtrObgnmZkyd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['final_data']\n",
        "y = pd.read_csv('sample_data/test_labels.csv',encoding='utf-8')\n",
        "y.replace(-1,1)\n",
        "vectorizer.adapt(X.values)\n",
        "X.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do_9ui7IZlhJ",
        "outputId": "1311e32a-de40-483c-8f24-a1ae48433c25"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['yo bitch ja rule succesful ever whats hating sad mofuckas bitch slap ur pethedic white faces get kiss ass guys sicken ja rule pride da music man dont diss shit nothin wrong bein like tupac brother fuckin white boys get things right next time',\n",
              "       'rfc title fine imo', 'sources zawe ashton lapland', ...,\n",
              "       'okinotorishima categories see changes agree correct gotten confused found acknowledging japan territorial rights okinotorishima however category acknowledge japan claim exclusive economic zone eez stemming okinotorishima category disputed eez',\n",
              "       'one founding nations eu germany law return quite similar israel actually true germany allows people whose ancestors citizens germany return afaik allow descendants anglo saxons return angeln saxony israel contrast allows jews return israel even trace particular ancestral line anyone lived modern state even mandate palestine',\n",
              "       'stop already bullshit welcome fool think kind explination enough well pity'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = y[y.columns[1:]].values\n"
      ],
      "metadata": {
        "id": "33EQuVZEh9vq"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxBITQXxkjY3",
        "outputId": "71ca1ce4-dc42-46ab-8412-572c13f3d7db"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1, -1, -1, -1, -1, -1],\n",
              "       [-1, -1, -1, -1, -1, -1],\n",
              "       [-1, -1, -1, -1, -1, -1],\n",
              "       ...,\n",
              "       [-1, -1, -1, -1, -1, -1],\n",
              "       [-1, -1, -1, -1, -1, -1],\n",
              "       [-1, -1, -1, -1, -1, -1]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.adapt(X.values)"
      ],
      "metadata": {
        "id": "Kr1i0vGVe5P0"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorized_text = vectorizer(X.values) #passing the numpy array to the vectorizer and vectorizing all text"
      ],
      "metadata": {
        "id": "zpSyozPvewLW"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorized_text # 159571 - no of entries in the dataset , #1800 - output seq length wich is the max num of words a sentence might have. 0 s are given if it does to have that many words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkYtRJgsZzLi",
        "outputId": "fa53df09-f856-4ca2-afc2-66b345b125e0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(153164, 1800), dtype=int64, numpy=\n",
              "array([[ 1344,   125,  2934, ...,     0,     0,     0],\n",
              "       [  906,   215,   510, ...,     0,     0,     0],\n",
              "       [   28, 87596,  6571, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [52615,   991,    11, ...,     0,     0,     0],\n",
              "       [    8,  5373,  2133, ...,     0,     0,     0],\n",
              "       [   86,   141,   599, ...,     0,     0,     0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))"
      ],
      "metadata": {
        "id": "M_w8uy4lhhhQ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(160000) #160000 - buffersize\n",
        "dataset = dataset.batch(16) #each batch has 16 samples\n",
        "dataset = dataset.prefetch(8) # helps bottlenecks\n",
        "testDataset = dataset.take(int(len(dataset)*1)) \n"
      ],
      "metadata": {
        "id": "nv1M2AucZzrj"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_batch_X , test_batch_y = testDataset.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "Ex_ejcYbYdyR"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R4eCPul8aLto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n"
      ],
      "metadata": {
        "id": "SQZzyHNnaTCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = CategoricalAccuracy()\n"
      ],
      "metadata": {
        "id": "9ldz2xABaU3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in testDataset.as_numpy_iterator(): \n",
        "    # Unpack the batch \n",
        "    X_true, y_true = batch;\n",
        "    # Make a prediction \n",
        "    yhat = model.predict(X_true);\n",
        "    \n",
        "    # Flatten the predictions\n",
        "    y_true = y_true.flatten();\n",
        "    yhat = yhat.flatten();\n",
        "    \n",
        "    pre.update_state(y_true, yhat);\n",
        "    re.update_state(y_true, yhat);\n",
        "    acc.update_state(y_true, yhat);\n"
      ],
      "metadata": {
        "id": "0tzMf24vaXbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
      ],
      "metadata": {
        "id": "Z8IRqRO9acOx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}